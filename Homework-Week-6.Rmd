---
title: "Homework-Week-6"
output: html_document
---
#[1]Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines.

###Your function should take the following arguments: p1 and n1 (no default) to pose as the estimated proportion and sample size (i.e., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample's proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default "two.sided") and conf.level (default 0.95), to be used in the same way as in the function t.test().
###When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative="less" or alternative="greater", the same as in the use of x and y in the function t.test().
###The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.
###The function should contain a check for the rules of thumb we have talked about ($n * p > 5$ and $n * (1-p) >5$) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.
###The function should return a list containing the members Z (the test statistic), P (the appropriate p-value), and CI (the two-sided CI with respect to confidence level).

```{R,echo=TRUE}

Z.prop.test<-function(p1,n1,p2=NULL,n2=NULL,p0,alternative = "two.sided",conf.level = 0.95){
  #this step set up the structure and default values for the function
  if(is.nul(p2)||is.null(n2)){
    #first criterion check determines whether we run a one sample or two sample test
    if(n1*p1<=5||n1*(1-p1)<=5){
      warning("Warning: Normal Dist Invalid")#Checking validity of normal distribution
      }
    z<-(p1-p0)/sqrt(p0(1-p0)/n1)
    CI <- (p1)+c(-1,1)*qnorm(conf.level+(1-conf.level)/2)*sqrt(p0*(1-p0)/n1)
  }else{ #second scenario in which p2 and n2 are not null - 2 sample test
    if(p1*n1<=5||n1*(1-p1)<=5||p2*n2<=5||n2*(1-p2)<=5){
      warning("Warning: Normal Dist Invalid")
    }#if validity is satisfied, a one sample test is run
    pstar<-(p1*n1+p2*n2)/(n1+n2)
    z<-(p2-p1-p0)/sqrt(pstar*(1-pstar)*((1/n1)+(1/n2)))
    CI <- sort((p1-p2)+c(-1,1)*qnorm(conf.level+(1-conf.level)/2)*sqrt(pstar*(1-pstar)*((1/n1)+(1/n2))))
  if(alternative=="greater"){ #if we specify "greater", we want a one-sided upper tail test like this:
    p<-pnorm(z,lower.tail=FALSE)
  }else if(alternative=="less"){ #if we specify "greater", we want a one-sided lower tail test like this:
    p<-pnorm(z,lower.tail = TRUE)
  }else if (alternative=="two.sided"){ #the default argument is for a two-tailed test like this:
    if(z>0){p<-2*pnorm(z,lower.tail = F)}
    if(z<0){p<-2*pnorm(z,lower.tail = T)}
  }
  return(list(z=z,p=p,CI=CI)) #return results in list format
  }
}
```

#[2] The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity ("MaxLongevity_m") measured in months from species' brain size ("Brain_Size_Species_Mean") measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size).
```{R}
library(curl)
f<-curl("https://raw.githubusercontent.com/difiore/ADA2016/master/KamilarAndCooperData.csv")
d<-read.csv(f,header=TRUE,sep = ",",stringsAsFactors = FALSE)
log_brain<-log(d$Brain_Size_Species_Mean)
log_longevity<-log(d$MaxLongevity_m)
df<-cbind(d,log_brain,log_longevity)
##Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot.

library(ggplot2)

##Maximum longevity regressed on brain size:

m<-lm(df$MaxLongevity_m~df$Brain_Size_Species_Mean,data=df)
summary(m)
lm_eqn = function(m) {

  l <- list(a = format(coef(m)[1], digits = 5),
      b = format(abs(coef(m)[2]), digits = 3),
      r2 = format(summary(m)$r.squared, digits = 3));
  if (coef(m)[2] >= 0)  {
    eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2,l)
  } else {
    eq <- substitute(italic(y) == a - b %.% italic(x)*","~~italic(r)^2~"="~r2,l)  
  }
  as.character(as.expression(eq));                 
}
regression_plot<-ggplot(data=df,aes(x=df$Brain_Size_Species_Mean,y=df$MaxLongevity_m))+xlab("Brain Size (g)")+ylab("Maximum Longevity (mo)")+geom_point()+geom_smooth(method="lm",formula=y~x)+ geom_text(aes(x = 350, y = 250, label = lm_eqn(lm(df$MaxLongevity_m ~ df$Brain_Size_Species_Mean, df))), parse = TRUE)
regression_plot

##Log-transformed maximum longevity regressed on log-transformed brain size:

log_m<-lm(df$log_longevity~df$log_brain,data=df)
summary(log_m)
lm_eqn = function(log_m) {

  l <- list(a = format(coef(log_m)[1], digits = 5),
      b = format(abs(coef(log_m)[2]), digits = 3),
      r2 = format(summary(log_m)$r.squared, digits = 3));
  if (coef(log_m)[2] >= 0)  {
    eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2,l)
  } else {
    eq <- substitute(italic(y) == a - b %.% italic(x)*","~~italic(r)^2~"="~r2,l)  
  }
  as.character(as.expression(eq));                 
}

log_regression_plot<-ggplot(data=df,aes(x=df$log_brain,y=df$log_longevity))+xlab("Log-Transformed Brain Size (g)")+ylab("Log-Transformed Maximum Longevity (mo)")+geom_point()+geom_smooth(method="lm",formula=y~x)+ geom_text(aes(x = 4.5, y = 4.7, label = lm_eqn(lm(df$log_longevity ~ df$log_brain, df))), parse = TRUE)
log_regression_plot

##Identify and interpret the point estimate of the slope ($\beta_1$), as well as the outcome of the test associated with the hypotheses H0: $\beta_1$ = 0; HA: $\beta_1$ â‰  0. Also, find a 90 percent CI for the slope ($\beta_1$) parameter.

##Original variables:
summary(m)
t<-coef(summary(m))
t<-data.frame(unlist(t))
colnames(t)<-c("Est", "SE", "t", "p")
t
t$calct<-(t$Est-0)/t$SE
t$calcp <- 2 * pt(t$calct, df = 998, lower.tail = FALSE)
t
t$lower <- t$Est - qt(0.95, df = 998) * t$SE
t$upper <- t$Est + qt(0.95, df = 998) * t$SE
ci <- c(t$lower, t$upper)  # by hand
ci
ci<-confint(m,level = 0.9)
ci
###Discussion: Beta1 is equal to ~1.218. This means that for every 1 gram increase in brain size we can expect an increase in maximum longevity of ~1.218 months. The p-value associated with beta1 is very well under 0.05; therefore we can reject the null hypothesis that beta1 = 0.

##Log-transformed variables:
summary(log_m)
log_t<-coef(summary(log_m))
log_t<-data.frame(unlist(log_t))
colnames(log_t)<-c("log_Est", "log_SE", "log_t", "log_p")
log_t
log_t$log_calct<-(log_t$log_Est-0)/log_t$log_SE
log_t$log_calcp <- 2 * pt(log_t$log_calct, df = 998, lower.tail = FALSE)
log_t
log_ci<-confint(log_m,level = 0.9)
log_ci

###Discussion: Beta1 for the log-transformed model is equal to ~0.2046. This means that for every 1 unit increase in brain size we can expect an increase in maximum longevity of ~0.2342 months, or about 7 days. Again, the p-value associated with beta1 is much less than 0.05, allowing us to reject the null hypothesis that beta1 = 0.


##Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.

##Original Variables:
ci<-predict(m,newdata =data.frame(Brain_Size_Species_Mean=df$Brain_Size_Species_Mean),interval="confidence",level=0.90)  # for a vector of values
head(ci)
df <- cbind(df, ci)
pi<-predict(m,newdata=data.frame(Brain_Size_Species_Mean=df$Brain_Size_Species_Mean),interval="prediction",level = 0.90)
colnames(pi)<-c("pi_fit","pi_lwr","pi_upr")
df<-cbind(df,pi)
regression_plot<-regression_plot+
  geom_line(aes(x=df$Brain_Size_Species_Mean,y=df$fit,colour="Regression_Line"))+
  geom_line(aes(x=df$Brain_Size_Species_Mean,y=df$lwr,colour="Confidence_Intervals"))+
  geom_line(aes(x=df$Brain_Size_Species_Mean,y=df$upr,colour="Confidence_Intervals"))+
  geom_line(data=df,aes(x=df$Brain_Size_Species_Mean,y=df$pi_lwr, colour="Prediction_Intervals"))+
  geom_line(data=df,aes(x=df$Brain_Size_Species_Mean,y=df$pi_upr,colour="Prediction_Intervals"))+
  scale_colour_manual(name="Legend",values = c(Regression_Line="blue",Confidence_Intervals="red",Prediction_Intervals="green"))+
  ggtitle("Linear Regression of Longevity on Brain Size")
regression_plot

##Log-transformed variables:
log_ci<-predict(log_m,newdata =data.frame(log_brain=df$log_brain),interval="confidence",level=0.90)
colnames(log_ci)<-c("log_fit","log_lwr","log_upr")
df <- cbind(df, log_ci)
log_pi<-predict(log_m,newdata=data.frame(log_brain=df$log_brain),interval="prediction",level = 0.90)
colnames(log_pi)<-c("log_pi_fit","log_pi_lwr","log_pi_upr")
df<-cbind(df,log_pi)
head(df)

log_regression_plot<-log_regression_plot+
  geom_line(aes(x=df$log_brain,y=df$log_fit,colour="Regression_Line"))+
  geom_line(aes(x=df$log_brain,y=df$log_lwr,colour="Confidence_Intervals"))+
  geom_line(aes(x=df$log_brain,y=df$log_upr,colour="Confidence_Intervals"))+
  geom_line(data=df,aes(x=df$log_brain,y=df$log_pi_lwr, colour="Prediction_Intervals"))+
  geom_line(data=df,aes(x=df$log_brain,y=df$log_pi_upr,colour="Prediction_Intervals"))+
  scale_colour_manual(name="Legend",values = c(Regression_Line="blue",Confidence_Intervals="red",Prediction_Intervals="green"))+
  ggtitle("Linear Regression of Longevity on Brain Size [log-Transformed]")
log_regression_plot

##Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?

##Original data:

<<<<<<< HEAD
m
beta1<-1.218
beta0<-248.952
y<-beta1*800+beta0
y #point estimate
confint(m,level=0.9)
ylwr<-1.036*800+130.54
yupr<-1.4*800+267.36
CI<-c(ylwr,yupr)
CI #Confidence interval

##Log-transformed data:

log_m
beta1<-0.2341
beta0<-4.879
y<-beta1*800+beta0
y #point estimate
confint(log_m,level=0.9)
ylwr<-0.2046*800+4.764
yupr<-0.2637*800+4.993
CI<-c(ylwr,yupr)
CI #Confidence interval

##Discussion: First of all, I know that this last section isn't technically right as I'm reporting confidence intervals and not prediction intervals. I know that we are meant to use the predict() function, but when I tried to format it as we did in class [predict(m,newdata=data.frame(Brain_Size_Species_Mean=800),interval="prediction",level=0.90)] I kept getting an error message that showed that it was trying to pull predicted intervals for all the values in that column rather than just predicting a point estimate and interval for 800 grams.. I'll be sure to come trouble-shoot this with you on Wednesday if I can't figure it out by then. However, to answer the question you posed, I think it is unlikely that either regression will provide a reliable prediction of longevity given their relatively low coefficients of determination. Also, from looking at the plots of the two regressions, the original variables are clearly very skewed to the left of the regrssion, and there is a lower level of certainty as x increases. For a brain size as high as 800 grams, we can not expect a realistic prediction from this model (as evidenced by the point estimate of ~1223 months for a brain size of 800g). In regard to which model is preferable, judging from the plots, the log-transformed data appears to adhere more closely to a normal distribution while also showing more consistency in confidence intervals. Overall, this would make the log-transformed model more conducive to predicting longevity from a wide range of brain sizes.
=======

##Log-transformed data:

>>>>>>> origin/master
